{
    "sourceFile": "App/Utils/ImageProcessor.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1745148233910,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1745148233910,
            "name": "Commit-0",
            "content": "import cv2\r\nimport numpy as np\r\nimport torch\r\nimport torch.nn.functional as F\r\nimport logging\r\nfrom pathlib import Path\r\nimport os\r\nfrom transformers import ViTFeatureExtractor, ViTForImageClassification, ViTImageProcessor\r\nfrom PIL import Image\r\nfrom torchvision import transforms\r\n\r\n\r\nclass ImageProcessor:\r\n    def __init__(self):\r\n        logging.getLogger(__name__).setLevel(logging.INFO)\r\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n        self.use_dl = False  # Default to traditional methods\r\n        self.edge_model = None\r\n        self.material_classifier = None\r\n        self.feature_extractor = None\r\n        self.material_classifier_initialized = False\r\n\r\n    def initialize_dl_model(self):\r\n        if self.edge_model is not None:\r\n            return\r\n\r\n        try:\r\n            logging.info(\"Initializing deep learning model...\")\r\n            # Try offline model first\r\n            model_path = Path(__file__).parent / 'models' / 'deeplabv3_resnet50.pth'\r\n            if model_path.exists():\r\n                # Add safe globals for model loading\r\n                torch.serialization.add_safe_globals(['DeepLabV3'])\r\n                self.edge_model = torch.load(\r\n                    model_path,\r\n                    weights_only=True,  # Load only weights to reduce memory\r\n                    map_location=self.device\r\n                )\r\n            else:\r\n                self.edge_model = torch.hub.load(\r\n                    'pytorch/vision:v0.10.0',\r\n                    'deeplabv3_resnet50',\r\n                    pretrained=True,\r\n                    force_reload=False,\r\n                    trust_repo=True\r\n                )\r\n                # Save model for offline use\r\n                os.makedirs(model_path.parent, exist_ok=True)\r\n                torch.save(self.edge_model, model_path, _use_new_zipfile_serialization=False)\r\n\r\n            self.edge_model.to(self.device)\r\n            self.edge_model.eval()\r\n            self.use_dl = True\r\n            logging.info(\"Deep learning model initialized successfully\")\r\n        except Exception as e:\r\n            self.use_dl = False\r\n            logging.warning(f\"Deep learning model initialization failed: {str(e)}\")\r\n            logging.info(\"Falling back to traditional methods\")\r\n            if torch.cuda.is_available():\r\n                torch.cuda.empty_cache()\r\n\r\n    def initialize_material_classifier(self):\r\n        if self.material_classifier is not None:\r\n            return\r\n\r\n        try:\r\n            logging.info(\"Initializing material classifier...\")\r\n            model_name = 'google/vit-base-patch16-224'\r\n            model_path = Path(__file__).parent / 'models' / 'material_classifier'\r\n\r\n            # Create models directory if it doesn't exist\r\n            os.makedirs(model_path.parent, exist_ok=True)\r\n\r\n            try:\r\n                # Configure model parameters\r\n                model_config = {\r\n                    'num_labels': 3,\r\n                    'id2label': {0: \"Sand\", 1: \"Gravel\", 2: \"Other\"},\r\n                    'label2id': {\"Sand\": 0, \"Gravel\": 1, \"Other\": 2},\r\n                    'ignore_mismatched_sizes': True,\r\n                    'low_cpu_mem_usage': True  # Enable memory optimization\r\n                }\r\n\r\n                # Initialize the classifier head for our custom classes\r\n                def init_classifier_head(model):\r\n                    model.classifier = torch.nn.Linear(model.config.hidden_size, 3)\r\n                    return model\r\n\r\n                if model_path.exists():\r\n                    logging.info(\"Loading model from local path...\")\r\n                    try:\r\n                        self.feature_extractor = ViTImageProcessor.from_pretrained(\r\n                            str(model_path),\r\n                            local_files_only=True\r\n                        )\r\n                        self.material_classifier = ViTForImageClassification.from_pretrained(\r\n                            str(model_path),\r\n                            local_files_only=True,\r\n                            **model_config\r\n                        )\r\n                    except Exception as local_error:\r\n                        logging.warning(f\"Failed to load local model: {str(local_error)}\")\r\n                        if os.path.exists(str(model_path)):\r\n                            import shutil\r\n                            shutil.rmtree(str(model_path))\r\n                        raise\r\n\r\n                if not model_path.exists():\r\n                    logging.info(\"Downloading pre-trained model...\")\r\n                    self.feature_extractor = ViTImageProcessor.from_pretrained(\r\n                        model_name\r\n                    )\r\n                    # Load base model and reinitialize classifier head\r\n                    base_model = ViTForImageClassification.from_pretrained(\r\n                        model_name,\r\n                        low_cpu_mem_usage=True  # Enable memory optimization\r\n                    )\r\n                    self.material_classifier = init_classifier_head(base_model)\r\n                    # Update config after head reinitialization\r\n                    self.material_classifier.config.update(model_config)\r\n\r\n                    # Save models for offline use\r\n                    logging.info(\"Saving model for offline use...\")\r\n                    os.makedirs(str(model_path), exist_ok=True)\r\n                    self.feature_extractor.save_pretrained(str(model_path))\r\n                    self.material_classifier.save_pretrained(str(model_path))\r\n\r\n                self.material_classifier.to(self.device)\r\n                self.material_classifier.eval()\r\n                self.material_classifier_initialized = True\r\n                logging.info(\"Material classifier initialized successfully\")\r\n            except Exception as model_error:\r\n                logging.error(f\"Model loading error: {str(model_error)}\")\r\n                raise\r\n        except Exception as e:\r\n            self.material_classifier_initialized = False\r\n            logging.error(f\"Material classifier initialization failed: {str(e)}\")\r\n            logging.warning(\"Material classification will be disabled\")\r\n            if torch.cuda.is_available():\r\n                torch.cuda.empty_cache()\r\n\r\n    def preprocess_image(self, image):\r\n        # Input validation\r\n        if image is None or not isinstance(image, np.ndarray):\r\n            raise ValueError(\"Invalid input image\")\r\n\r\n        # Convert to grayscale and apply noise reduction\r\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n        denoised = cv2.fastNlMeansDenoising(gray)\r\n\r\n        # Apply contrast enhancement\r\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\r\n        enhanced = clahe.apply(denoised)\r\n\r\n        # Apply Gaussian blur for edge detection\r\n        blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)\r\n\r\n        return blurred\r\n\r\n    def classify_material(self, image):\r\n        if not hasattr(self, 'material_classifier_initialized') or not self.material_classifier_initialized:\r\n            # Initialize classifier if not already done\r\n            self.initialize_material_classifier()\r\n            if not self.material_classifier_initialized:\r\n                logging.warning(\"Material classifier not initialized, skipping classification\")\r\n                return \"Unknown\", 0.0\r\n\r\n        try:\r\n            # Input validation\r\n            if image is None or not isinstance(image, np.ndarray):\r\n                raise ValueError(\"Invalid input image\")\r\n            if len(image.shape) != 3 or image.shape[2] != 3:\r\n                raise ValueError(\"Image must be a 3-channel BGR image\")\r\n\r\n            # Convert BGR to RGB and resize\r\n            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n            rgb_image = cv2.resize(rgb_image, (224, 224))\r\n            pil_image = Image.fromarray(rgb_image)\r\n\r\n            # Prepare image for ViT with normalization\r\n            inputs = self.feature_extractor(images=pil_image, return_tensors=\"pt\", do_normalize=True)\r\n            inputs = {k: v.to(self.device) for k, v in inputs.items()}\r\n\r\n            # Get prediction\r\n            with torch.no_grad():\r\n                outputs = self.material_classifier(**inputs)\r\n                logits = outputs.logits\r\n                probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\r\n                predicted_class = torch.argmax(probabilities).item()\r\n                confidence = probabilities[predicted_class].item()\r\n\r\n                # Clear GPU memory immediately after prediction\r\n                del outputs, logits, probabilities\r\n                if torch.cuda.is_available():\r\n                    torch.cuda.empty_cache()\r\n\r\n            material_types = {0: \"Sand\", 1: \"Gravel\", 2: \"Other\"}\r\n            return material_types[predicted_class], confidence\r\n\r\n        except ValueError as e:\r\n            logging.error(f\"Invalid input: {str(e)}\")\r\n            return \"Unknown\", 0.0\r\n        except Exception as e:\r\n            logging.error(f\"Material classification failed: {str(e)}\")\r\n            return \"Unknown\", 0.0\r\n        finally:\r\n            # Clean up any GPU memory\r\n            if torch.cuda.is_available():\r\n                torch.cuda.empty_cache()\r\n\r\n    @staticmethod\r\n    def detect_edges(image):\r\n        # Convert to grayscale if needed\r\n        if len(image.shape) == 3:\r\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n        else:\r\n            gray = image\r\n\r\n        # Apply bilateral filter to reduce noise while preserving edges\r\n        denoised = cv2.bilateralFilter(gray, 9, 75, 75)\r\n\r\n        # Apply adaptive thresholding to handle varying lighting conditions\r\n        thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\r\n                                       cv2.THRESH_BINARY, 11, 2)\r\n\r\n        # Use Canny edge detection with automatic threshold calculation\r\n        median = np.median(gray)\r\n        sigma = 0.33\r\n        lower = int(max(0, (1.0 - sigma) * median))\r\n        upper = int(min(255, (1.0 + sigma) * median))\r\n        edges = cv2.Canny(denoised, lower, upper)\r\n\r\n        # Enhance edges using morphological operations\r\n        kernel = np.ones((3, 3), np.uint8)\r\n        edges = cv2.dilate(edges, kernel, iterations=1)\r\n        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\r\n\r\n        return edges, thresh\r\n\r\n    @staticmethod\r\n    def detect_corners(image, max_corners=4):\r\n        corners = cv2.goodFeaturesToTrack(\r\n            image,\r\n            maxCorners=max_corners,\r\n            qualityLevel=0.01,\r\n            minDistance=100\r\n        )\r\n        if corners is not None:\r\n            corners = np.float32(corners)\r\n            corners = corners.reshape(-1, 2)\r\n        return corners\r\n\r\n    @staticmethod\r\n    def sort_corners(corners):\r\n        center = np.mean(corners, axis=0)\r\n        angles = np.arctan2(corners[:, 1] - center[1], corners[:, 0] - center[0])\r\n        return corners[np.argsort(angles)]\r\n\r\n    @staticmethod\r\n    def enhance_edges(image):\r\n        \"\"\"Enhance edges for better corner detection\"\"\"\r\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\r\n        enhanced = clahe.apply(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\r\n        return enhanced\r\n\r\n    @staticmethod\r\n    def get_cube_mask(image):\r\n        \"\"\"Extract cube mask using adaptive thresholding\"\"\"\r\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n        blur = cv2.GaussianBlur(gray, (5, 5), 0)\r\n        thresh = cv2.adaptiveThreshold(\r\n            blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\r\n            cv2.THRESH_BINARY, 11, 2\r\n        )\r\n        return thresh\r\n\r\n    def detect_pile_edges(self, image):\r\n        try:\r\n            # Input validation\r\n            if image is None or not isinstance(image, np.ndarray):\r\n                raise ValueError(\"Invalid input image\")\r\n\r\n            # Convert and enhance\r\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n            denoised = cv2.fastNlMeansDenoising(gray)\r\n            enhanced = self.enhance_edges(denoised)\r\n\r\n            # Create visualization dictionary\r\n            viz_steps = {\r\n                'original': image.copy(),\r\n                'grayscale': cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR),\r\n                'denoised': cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR),\r\n                'enhanced': cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)\r\n            }\r\n\r\n            if self.use_dl:\r\n                try:\r\n                    # Initialize model if not already done\r\n                    self.initialize_dl_model()\r\n\r\n                    # Prepare for deep learning\r\n                    input_tensor = torch.from_numpy(enhanced).float()\r\n                    input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)\r\n                    input_tensor = F.interpolate(input_tensor, size=(224, 224))\r\n                    input_tensor = input_tensor.to(self.device)\r\n\r\n                    with torch.no_grad():\r\n                        output = self.edge_model(input_tensor)['out'][0]\r\n                        edges_dl = F.interpolate(output.unsqueeze(0),\r\n                                                 size=image.shape[:2],\r\n                                                 mode='bilinear').squeeze(0)\r\n                        edges_dl = edges_dl.argmax(0).cpu().numpy()\r\n\r\n                    # Traditional edge detection with adaptive thresholding\r\n                    blur = cv2.GaussianBlur(enhanced, (5, 5), 0)\r\n                    edges_cv = cv2.Canny(blur, 50, 150)\r\n\r\n                    # Combine edges with morphological operations\r\n                    edges = cv2.bitwise_and(edges_dl.astype(np.uint8), edges_cv)\r\n                    kernel = np.ones((3, 3), np.uint8)\r\n                    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\r\n\r\n                    # Add visualization steps\r\n                    viz_steps['dl_edges'] = cv2.cvtColor(edges_dl.astype(np.uint8) * 255, cv2.COLOR_GRAY2BGR)\r\n                    viz_steps['cv_edges'] = cv2.cvtColor(edges_cv, cv2.COLOR_GRAY2BGR)\r\n\r\n                finally:\r\n                    # Clean GPU memory\r\n                    if torch.cuda.is_available():\r\n                        torch.cuda.empty_cache()\r\n            else:\r\n                # Enhanced traditional edge detection\r\n                blur = cv2.GaussianBlur(enhanced, (5, 5), 0)\r\n\r\n                # Adaptive thresholding\r\n                thresh = cv2.adaptiveThreshold(\r\n                    blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\r\n                    cv2.THRESH_BINARY, 11, 2\r\n                )\r\n\r\n                # Multi-scale edge detection\r\n                edges_low = cv2.Canny(blur, 30, 100)\r\n                edges_high = cv2.Canny(blur, 70, 200)\r\n                edges = cv2.addWeighted(edges_low, 0.5, edges_high, 0.5, 0)\r\n\r\n                # Combine with threshold\r\n                edges = cv2.bitwise_and(edges, thresh)\r\n\r\n                # Clean up edges\r\n                kernel = np.ones((3, 3), np.uint8)\r\n                edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\r\n\r\n                # Add visualization steps\r\n                viz_steps['threshold'] = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\r\n                viz_steps['edges_low'] = cv2.cvtColor(edges_low, cv2.COLOR_GRAY2BGR)\r\n                viz_steps['edges_high'] = cv2.cvtColor(edges_high, cv2.COLOR_GRAY2BGR)\r\n\r\n            # Post-process edges\r\n            processed_edges = self.post_process_edges(edges)\r\n\r\n            # Create colored edge visualization\r\n            edge_viz = image.copy()\r\n            edge_viz[processed_edges > 0] = [0, 255, 0]  # Green color for detected edges\r\n\r\n            # Add final visualizations\r\n            viz_steps['detected_edges'] = edge_viz\r\n            viz_steps['final_edges'] = cv2.cvtColor(processed_edges, cv2.COLOR_GRAY2BGR)\r\n\r\n            # Display visualization steps\r\n            self.display_edge_detection_steps(viz_steps)\r\n\r\n            return processed_edges\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Edge detection failed: {str(e)}\")\r\n            raise\r\n\r\n    def display_edge_detection_steps(self, viz_steps):\r\n        \"\"\"Display intermediate steps of edge detection process.\r\n\r\n        Args:\r\n            viz_steps (dict): Dictionary containing visualization images for each step\r\n        \"\"\"\r\n        try:\r\n            # Create a figure with subplots\r\n            num_steps = len(viz_steps)\r\n            cols = min(3, num_steps)  # Maximum 3 columns\r\n            rows = (num_steps + cols - 1) // cols\r\n\r\n            plt.figure(figsize=(15, 5 * rows))\r\n\r\n            # Display each step\r\n            for idx, (step_name, step_img) in enumerate(viz_steps.items(), 1):\r\n                plt.subplot(rows, cols, idx)\r\n                plt.imshow(cv2.cvtColor(step_img, cv2.COLOR_BGR2RGB))\r\n                plt.title(step_name.replace('_', ' ').title())\r\n                plt.axis('off')\r\n\r\n            plt.tight_layout()\r\n            plt.show()\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Failed to display edge detection steps: {str(e)}\")\r\n        \"\"\"Display the edge detection visualization steps.\"\"\"\r\n        try:\r\n            # Create a figure with subplots\r\n            rows = (len(viz_steps) + 2) // 3  # 3 images per row\r\n            fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))\r\n            fig.suptitle('Edge Detection Steps', fontsize=16)\r\n\r\n            # Flatten axes for easier iteration\r\n            axes = axes.flatten() if rows > 1 else [axes]\r\n\r\n            # Display each step\r\n            for idx, (step_name, step_img) in enumerate(viz_steps.items()):\r\n                axes[idx].imshow(cv2.cvtColor(step_img, cv2.COLOR_BGR2RGB))\r\n                axes[idx].set_title(step_name.replace('_', ' ').title())\r\n                axes[idx].axis('off')\r\n\r\n            # Hide empty subplots\r\n            for idx in range(len(viz_steps), len(axes)):\r\n                axes[idx].axis('off')\r\n\r\n            plt.tight_layout()\r\n            plt.show()\r\n\r\n        except Exception as e:\r\n            logging.warning(f\"Failed to display edge detection steps: {str(e)}\")\r\n\r\n    def post_process_edges(self, edges):\r\n        # Post-processing\r\n        kernel = np.ones((3, 3), np.uint8)\r\n        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\r\n\r\n        return edges\r\n\r\n    def process_image_pair(self, top_image, front_image):\r\n        \"\"\"Process both images and return enhanced results with edges and corners\"\"\"\r\n        # Get pile edges\r\n        top_edges = self.detect_pile_edges(top_image)\r\n        front_edges = self.detect_pile_edges(front_image)\r\n\r\n        # Enhance edges\r\n        top_enhanced = self.enhance_edges(top_image)\r\n        front_enhanced = self.enhance_edges(front_image)\r\n\r\n        # Get masks\r\n        top_mask = self.get_cube_mask(top_image)\r\n        front_mask = self.get_cube_mask(front_image)\r\n\r\n        # Detect corners with masks\r\n        top_corners = self.detect_corners(top_enhanced * (top_mask // 255))\r\n        front_corners = self.detect_corners(front_enhanced * (front_mask // 255))\r\n\r\n        # Detect contours\r\n        top_contours, _ = cv2.findContours(top_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n        front_contours, _ = cv2.findContours(front_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n        # Get points along contours\r\n        top_points = np.vstack([cont.reshape(-1, 2) for cont in top_contours]) if len(top_contours) > 0 else np.array(\r\n            [])\r\n        front_points = np.vstack([cont.reshape(-1, 2) for cont in front_contours]) if len(\r\n            front_contours) > 0 else np.array([])\r\n\r\n        # Visualize results\r\n        self.visualize_detection_results(\r\n            top_image, front_image,\r\n            top_edges, front_edges,\r\n            top_corners, front_corners,\r\n            top_contours, front_contours\r\n        )\r\n\r\n        return {\r\n            'top_points': top_points,\r\n            'front_points': front_points,\r\n            'top_edges': top_edges,\r\n            'front_edges': front_edges,\r\n            'top_corners': top_corners,\r\n            'front_corners': front_corners,\r\n            'top_enhanced': top_enhanced,\r\n            'front_enhanced': front_enhanced,\r\n            'top_mask': top_mask,\r\n            'front_mask': front_mask\r\n        }\r\n\r\n    def visualize_detection_results(self, top_image, front_image, top_edges, front_edges,\r\n                                    top_corners, front_corners, top_contours, front_contours,\r\n                                    output_path=None):  # Add output_path argument\r\n        \"\"\"Visualize detection results on original images. Saves if output_path is provided.\"\"\"\r\n        try:\r\n            # Create copies for visualization\r\n            top_viz = top_image.copy()\r\n            front_viz = front_image.copy()\r\n\r\n            # Draw edges\r\n            top_viz[top_edges > 0] = [0, 255, 0]  # Green edges\r\n            front_viz[front_edges > 0] = [0, 255, 0]\r\n\r\n            # Draw contours\r\n            cv2.drawContours(top_viz, top_contours, -1, (255, 0, 0), 2)  # Blue contours\r\n            cv2.drawContours(front_viz, front_contours, -1, (255, 0, 0), 2)\r\n\r\n            # Draw corners\r\n            if top_corners is not None:\r\n                for corner in top_corners:\r\n                    cv2.circle(top_viz, tuple(corner.astype(int)), 5, (0, 0, 255), -1)  # Red corners\r\n            if front_corners is not None:\r\n                for corner in front_corners:\r\n                    cv2.circle(front_viz, tuple(corner.astype(int)), 5, (0, 0, 255), -1)\r\n\r\n            # Display or Save results\r\n            plt.figure(figsize=(12, 6))\r\n\r\n            plt.subplot(121)\r\n            plt.imshow(cv2.cvtColor(top_viz, cv2.COLOR_BGR2RGB))\r\n            plt.title('Top View Detection Results')\r\n            plt.axis('off')\r\n\r\n            plt.subplot(122)\r\n            plt.imshow(cv2.cvtColor(front_viz, cv2.COLOR_BGR2RGB))\r\n            plt.title('Front View Detection Results')\r\n            plt.axis('off')\r\n\r\n            plt.tight_layout()\r\n\r\n            if output_path:\r\n                plt.savefig(output_path)  # Save the figure\r\n                logging.info(f\"Detection visualization saved to {output_path}\")\r\n                plt.close()  # Close the plot to free memory\r\n\r\n        except Exception as e:\r\n            logging.warning(f\"Failed to visualize detection results: {str(e)}\")\r\n\r\n    def create_object_mask(self, image):\r\n        \"\"\"Create a binary mask for object segmentation using adaptive thresholding and contour detection.\"\"\"\r\n        try:\r\n            # Convert to grayscale if needed\r\n            if len(image.shape) == 3:\r\n                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n            else:\r\n                gray = image.copy()\r\n\r\n            # Apply adaptive thresholding\r\n            blur = cv2.GaussianBlur(gray, (5, 5), 0)\r\n            thresh = cv2.adaptiveThreshold(\r\n                blur,\r\n                255,\r\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\r\n                cv2.THRESH_BINARY_INV,\r\n                11,\r\n                2\r\n            )\r\n\r\n            # Find contours\r\n            contours, _ = cv2.findContours(\r\n                thresh,\r\n                cv2.RETR_EXTERNAL,\r\n                cv2.CHAIN_APPROX_SIMPLE\r\n            )\r\n\r\n            # Create empty mask\r\n            mask = np.zeros_like(gray)\r\n\r\n            if contours:\r\n                # Find largest contour\r\n                largest_contour = max(contours, key=cv2.contourArea)\r\n                area = cv2.contourArea(largest_contour)\r\n\r\n                if area > 100:  # Minimum area threshold\r\n                    # Fill the contour\r\n                    cv2.drawContours(mask, [largest_contour], -1, 255, -1)\r\n\r\n                    # Apply morphological operations to clean up the mask\r\n                    kernel = np.ones((5, 5), np.uint8)\r\n                    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\r\n                    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\r\n\r\n            return mask\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Mask creation failed: {str(e)}\")\r\n            return None\r\n\r\n    def apply_mask_to_depth(self, depth_map, mask):\r\n        \"\"\"Apply binary mask to depth map for accurate volume calculation.\"\"\"\r\n        if depth_map is None or mask is None:\r\n            return None\r\n\r\n        try:\r\n            # Ensure mask and depth map have same dimensions\r\n            if depth_map.shape != mask.shape:\r\n                mask = cv2.resize(mask, (depth_map.shape[1], depth_map.shape[0]))\r\n\r\n            # Convert mask to binary\r\n            binary_mask = (mask > 0).astype(np.uint8)\r\n\r\n            # Apply mask to depth map\r\n            masked_depth = depth_map.copy()\r\n            masked_depth[binary_mask == 0] = 0\r\n\r\n            return masked_depth\r\n\r\n        except Exception as e:\r\n            logging.error(f\"Depth map masking failed: {str(e)}\")\r\n            return None\r\n"
        }
    ]
}
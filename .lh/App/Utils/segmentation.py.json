{
    "sourceFile": "App/Utils/segmentation.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1745147723237,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1745152043141,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,20 +4,24 @@\n from PIL import Image, ImageTk\r\n import cv2\r\n import numpy as np\r\n from ultralytics import YOLO\r\n-import logging  # Use logging instead of print/messagebox\r\n+import logging\r\n+import os  # Needed for visualize_segmentation\r\n \r\n # Configure logging\r\n logger = logging.getLogger(__name__)\r\n \r\n-# Load the model once when the module is imported.\r\n+# --- Load YOLO Model ---\r\n+MODEL_PATH = \"yolov8n.pt\"  # Or provide an absolute path / path relative to project root\r\n+yolo_model = None\r\n try:\r\n-    model = YOLO(\"yolov8n.pt\")  # Standard YOLOv8 nano model\r\n-    logger.info(\"YOLOv8 model loaded successfully.\")\r\n+    # Consider checking os.path.exists(MODEL_PATH) if path is not guaranteed\r\n+    yolo_model = YOLO(MODEL_PATH)\r\n+    logger.info(f\"YOLOv8 model loaded successfully from {MODEL_PATH}.\")\r\n except Exception as e:\r\n-    logger.error(f\"Failed to load YOLO model: {e}\", exc_info=True)\r\n-    model = None  # Set model to None if loading fails\r\n+    logger.error(f\"Failed to load YOLO model from {MODEL_PATH}: {e}\", exc_info=True)\r\n+    yolo_model = None\r\n \r\n \r\n def perform_segmentation(image: np.ndarray):\r\n     \"\"\"\r\n@@ -27,69 +31,56 @@\n     Args:\r\n         image: A NumPy array representing the preprocessed image (BGR format).\r\n \r\n     Returns:\r\n-        A dictionary containing segmentation results, e.g.,\r\n-        {'mask': binary_mask, 'contours': list_of_contours, 'yolo_results': yolo_results_object}\r\n+        A dictionary containing segmentation results: {'mask': binary_mask, 'contours': list_of_contours}\r\n         Returns None if processing fails.\r\n     \"\"\"\r\n     if image is None or image.size == 0:\r\n-        logger.error(\"perform_segmentation received an invalid image.\")\r\n+        logger.error(\"perform_segmentation received an invalid or empty image.\")\r\n         return None\r\n-\r\n-    logger.info(f\"Performing segmentation on image with shape: {image.shape}\")\r\n-\r\n+    logger.info(f\"Starting segmentation for image with shape: {image.shape}, dtype: {image.dtype}\")\r\n     try:\r\n         # --- Basic Segmentation (Thresholding & Contours) ---\r\n-        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n-        # Apply CLAHE for contrast enhancement - useful for varying lighting\r\n+        if len(image.shape) == 3 and image.shape[2] == 3:\r\n+            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n+        elif len(image.shape) == 2:\r\n+            gray = image  # Already grayscale\r\n+        else:\r\n+            logger.error(f\"Unsupported image shape for grayscale conversion: {image.shape}\")\r\n+            return None\r\n+\r\n         clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\r\n         enhanced = clahe.apply(gray)\r\n \r\n-        # Adaptive thresholding often works well for finding edges/regions\r\n+        # --- Parameters to Tune ---\r\n+        block_size = 25  # Must be odd, > 1\r\n+        C = 4\r\n         mask = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\r\n-                                     cv2.THRESH_BINARY_INV, 25, 4)  # Adjust block size (25) and C (4) as needed\r\n+                                     cv2.THRESH_BINARY_INV, block_size, C)\r\n \r\n-        # Morphological operations to clean up the mask\r\n-        kernel_size = 5  # Adjust kernel size as needed\r\n+        kernel_size = 5\r\n+        iterations_close = 1\r\n+        iterations_open = 1\r\n         kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\r\n-        # Closing fills small holes\r\n-        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\r\n-        # Opening removes small noise specks\r\n-        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\r\n+        mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations_close)\r\n+        mask_opened = cv2.morphologyEx(mask_closed, cv2.MORPH_OPEN, kernel, iterations=iterations_open)\r\n \r\n-        # Find contours on the cleaned mask\r\n-        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n+        contours, _ = cv2.findContours(mask_opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n \r\n-        # Filter contours based on area (adjust min_area as needed)\r\n         min_contour_area = 300\r\n         filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\r\n+        logger.info(f\"Filtered contours by area (> {min_contour_area}): {len(filtered_contours)} remaining.\")\r\n \r\n         # Create a final mask from filtered contours\r\n-        filtered_mask = np.zeros_like(mask)\r\n+        filtered_mask = np.zeros_like(mask_opened)\r\n         cv2.drawContours(filtered_mask, filtered_contours, -1, 255, -1)  # Draw filled contours\r\n \r\n-        logger.info(f\"Found {len(filtered_contours)} significant contours.\")\r\n-\r\n-        # --- Optional: Enhance with YOLO ---\r\n-        yolo_results = None\r\n-        if model is not None:\r\n-            try:\r\n-                # Run YOLO detection on the original image\r\n-                results = model(image, verbose=False)  # verbose=False reduces console output\r\n-                yolo_results = results[0]  # Get results for the first (only) image\r\n-                logger.info(f\"YOLO detected {len(yolo_results.boxes)} objects.\")\r\n-            except Exception as yolo_err:\r\n-                logger.error(f\"Error during YOLO detection: {yolo_err}\", exc_info=True)\r\n-        else:\r\n-            logger.warning(\"YOLO model not loaded, skipping YOLO detection.\")\r\n-\r\n-        # Return results in a structured way\r\n         segmentation_output = {\r\n             'mask': filtered_mask,\r\n             'contours': filtered_contours,\r\n-            'yolo_results': yolo_results  # Can be None if YOLO fails or isn't used\r\n         }\r\n+        logger.info(\"Segmentation completed successfully.\")\r\n         return segmentation_output\r\n \r\n     except cv2.error as cv_err:\r\n         logger.error(f\"OpenCV error during segmentation: {cv_err}\", exc_info=True)\r\n@@ -98,137 +89,66 @@\n         logger.error(f\"Unexpected error during segmentation: {e}\", exc_info=True)\r\n         return None\r\n \r\n \r\n-class SandPileApp:\r\n-    def __init__(self, root):\r\n-        self.root = root\r\n-        self.root.title(\"Sand Pile Volume Estimator\")\r\n-        self.material_type = tk.StringVar(value=\"Sand\")\r\n+def visualize_segmentation(original_image: np.ndarray, segmentation_data: dict, output_path: str):\r\n+    \"\"\"\r\n+    Draws the segmentation mask overlay onto the original image and saves it.\r\n \r\n-        self.top_image_path = None\r\n-        self.front_image_path = None\r\n-        self.tk_images = []\r\n+    Args:\r\n+        original_image: The original BGR image (NumPy array).\r\n+        segmentation_data: The dictionary returned by perform_segmentation (must contain 'mask').\r\n+        output_path: The full path where the visualization image will be saved.\r\n \r\n-        self.create_widgets()\r\n+    Returns:\r\n+        bool: True if visualization was saved successfully, False otherwise.\r\n+    \"\"\"\r\n+    if original_image is None or segmentation_data is None or 'mask' not in segmentation_data:\r\n+        logger.error(\"visualize_segmentation: Invalid input image or segmentation data.\")\r\n+        return False\r\n+    if not output_path:\r\n+        logger.error(\"visualize_segmentation: Output path not provided.\")\r\n+        return False\r\n \r\n-    def create_widgets(self):\r\n-        frame = ttk.Frame(self.root)\r\n-        frame.pack(padx=10, pady=10)\r\n+    mask = segmentation_data['mask']\r\n+    if mask is None or mask.shape[:2] != original_image.shape[:2]:\r\n+        logger.error(\"visualize_segmentation: Mask is invalid or dimensions mismatch.\")\r\n+        return False\r\n \r\n-        ttk.Label(frame, text=\"Select Material:\").grid(row=0, column=0, sticky='w')\r\n-        ttk.Combobox(frame, textvariable=self.material_type, values=[\"Sand\", \"10mm Gravel\", \"20mm Gravel\"]).grid(row=0, column=1)\r\n+    try:\r\n+        # Create a color overlay for the mask (e.g., semi-transparent blue)\r\n+        color_mask = np.zeros_like(original_image)\r\n+        color_mask[mask == 255] = [255, 0, 0]  # Blue color for mask area\r\n \r\n-        ttk.Button(frame, text=\"Upload Top View\", command=self.upload_top).grid(row=1, column=0, pady=5)\r\n-        ttk.Button(frame, text=\"Upload Front View\", command=self.upload_front).grid(row=1, column=1, pady=5)\r\n-        ttk.Button(frame, text=\"Process\", command=self.process).grid(row=2, column=0, columnspan=2, pady=10)\r\n+        # Blend the original image and the color mask\r\n+        alpha = 0.4  # Transparency factor\r\n+        overlay_image = cv2.addWeighted(original_image, 1, color_mask, alpha, 0)\r\n \r\n-        self.result_label = ttk.Label(frame, text=\"Detection Results Will Appear Below\", font=(\"Arial\", 10, \"bold\"))\r\n-        self.result_label.grid(row=3, column=0, columnspan=2)\r\n+        # Optionally draw contours\r\n+        contours = segmentation_data.get('contours')\r\n+        if contours:\r\n+            cv2.drawContours(overlay_image, contours, -1, (0, 255, 0), 1)  # Green contours\r\n \r\n-        self.canvas = tk.Canvas(self.root, width=1800, height=1100)\r\n-        self.canvas.pack()\r\n+        # Save the result\r\n+        # Ensure directory exists\r\n+        output_dir = os.path.dirname(output_path)\r\n+        if not os.path.exists(output_dir):\r\n+            try:\r\n+                os.makedirs(output_dir)\r\n+            except OSError as e:\r\n+                logger.error(f\"Could not create directory {output_dir}: {e}\")\r\n+                return False\r\n \r\n-    def upload_top(self):\r\n-        self.top_image_path = filedialog.askopenfilename()\r\n-        messagebox.showinfo(\"Top View\", f\"Loaded: {self.top_image_path}\")\r\n+        success = cv2.imwrite(output_path, overlay_image)\r\n+        if success:\r\n+            logger.info(f\"Segmentation visualization saved to: {output_path}\")\r\n+            return True\r\n+        else:\r\n+            logger.error(f\"Failed to save segmentation visualization to: {output_path}\")\r\n+            return False\r\n \r\n-    def upload_front(self):\r\n-        self.front_image_path = filedialog.askopenfilename()\r\n-        messagebox.showinfo(\"Front View\", f\"Loaded: {self.front_image_path}\")\r\n-\r\n-    def preprocess(self, path):\r\n-        img = cv2.imread(path)\r\n-        return cv2.resize(img, (640, 640))\r\n-\r\n-    def background_subtract(self, img):\r\n-        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n-        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\r\n-        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\r\n-        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n-        mask = np.zeros_like(gray)\r\n-        for cnt in contours:\r\n-            if cv2.contourArea(cnt) > 1000:\r\n-                cv2.drawContours(mask, [cnt], -1, 255, -1)\r\n-        return mask\r\n-\r\n-    def extract_foreground(self, img):\r\n-        mask = self.background_subtract(img)\r\n-        inverted_mask = cv2.bitwise_not(mask)  # 🔄 Invert the mask\r\n-        foreground = np.zeros_like(img)\r\n-        for c in range(3):\r\n-            foreground[:, :, c] = img[:, :, c] * (inverted_mask // 255)\r\n-        return foreground\r\n-\r\n-    def segment(self, img):\r\n-        segmentation_result = perform_segmentation(img)\r\n-        if segmentation_result:\r\n-            return cv2.bitwise_and(img, img, mask=segmentation_result['mask'])\r\n-        return img\r\n-\r\n-    def detect_objects(self, img):\r\n-        results = model(img)\r\n-        annotated = results[0].plot()\r\n-        labels = [model.names[int(cls)] for cls in results[0].boxes.cls.cpu().numpy()]\r\n-        return annotated, labels\r\n-\r\n-    def show_image(self, img, x, y, label):\r\n-        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n-        pil_img = Image.fromarray(img_rgb)\r\n-        pil_img = pil_img.resize((280, 280))\r\n-        tk_img = ImageTk.PhotoImage(pil_img)\r\n-\r\n-        self.canvas.create_image(x, y, anchor=\"nw\", image=tk_img)\r\n-        self.canvas.create_text(x + 140, y - 10, text=label, font=(\"Arial\", 10, \"bold\"))\r\n-        self.tk_images.append(tk_img)\r\n-\r\n-    def show_raw_input(self, path, x, y, label):\r\n-        img = Image.open(path).resize((280, 280))\r\n-        tk_img = ImageTk.PhotoImage(img)\r\n-        self.canvas.create_image(x, y, anchor=\"nw\", image=tk_img)\r\n\\ No newline at end of file\n-        self.canvas.create_text(x + 140, y - 10, text=label, font=(\"Arial\", 10, \"bold\"))\r\n-        self.tk_images.append(tk_img)\r\n-\r\n-    def process(self):\r\n-        if not self.top_image_path or not self.front_image_path:\r\n-            messagebox.showerror(\"Error\", \"Please upload both views.\")\r\n-            return\r\n-\r\n-        self.canvas.delete(\"all\")\r\n-        self.tk_images.clear()\r\n-\r\n-        self.show_raw_input(self.top_image_path, 50, 50, \"Input - Top View\")\r\n-        self.show_raw_input(self.front_image_path, 50, 400, \"Input - Front View\")\r\n-\r\n-        # Top View Processing\r\n-        top_img = self.preprocess(self.top_image_path)\r\n-        top_fg = self.extract_foreground(top_img)\r\n-        top_seg = self.segment(top_fg)\r\n-        top_detected, top_labels = self.detect_objects(top_seg)\r\n-\r\n-        # Front View Processing\r\n-        front_img = self.preprocess(self.front_image_path)\r\n-        front_fg = self.extract_foreground(front_img)\r\n-        front_seg = self.segment(front_fg)\r\n-        front_detected, front_labels = self.detect_objects(front_seg)\r\n-\r\n-        # Display Results\r\n-        self.show_image(top_fg, 350, 50, \"Top - Foreground\")\r\n-        self.show_image(top_seg, 650, 50, \"Top - Segmented\")\r\n-        self.show_image(top_detected, 950, 50, \"Top - Detection\")\r\n-\r\n-        self.show_image(front_fg, 350, 400, \"Front - Foreground\")\r\n-        self.show_image(front_seg, 650, 400, \"Front - Segmented\")\r\n-        self.show_image(front_detected, 950, 400, \"Front - Detection\")\r\n-\r\n-        result_text = (\r\n-            f\"Material: {self.material_type.get()}\\n\\n\"\r\n-            f\"Top View Detected: {top_labels}\\n\"\r\n-            f\"Front View Detected: {front_labels}\"\r\n-        )\r\n-        self.result_label.config(text=result_text)\r\n-\r\n-\r\n-if __name__ == \"__main__\":\r\n-    root = tk.Tk()\r\n-    app = SandPileApp(root)\r\n-    root.mainloop()\n+    except cv2.error as cv_err:\r\n+        logger.error(f\"OpenCV error during segmentation visualization: {cv_err}\", exc_info=True)\r\n+        return False\r\n+    except Exception as e:\r\n+        logger.error(f\"Unexpected error during segmentation visualization: {e}\", exc_info=True)\r\n+        return False\n\\ No newline at end of file\n"
                }
            ],
            "date": 1745147723237,
            "name": "Commit-0",
            "content": "import tkinter as tk\r\nfrom tkinter import filedialog, messagebox\r\nfrom tkinter import ttk\r\nfrom PIL import Image, ImageTk\r\nimport cv2\r\nimport numpy as np\r\nfrom ultralytics import YOLO\r\nimport logging  # Use logging instead of print/messagebox\r\n\r\n# Configure logging\r\nlogger = logging.getLogger(__name__)\r\n\r\n# Load the model once when the module is imported.\r\ntry:\r\n    model = YOLO(\"yolov8n.pt\")  # Standard YOLOv8 nano model\r\n    logger.info(\"YOLOv8 model loaded successfully.\")\r\nexcept Exception as e:\r\n    logger.error(f\"Failed to load YOLO model: {e}\", exc_info=True)\r\n    model = None  # Set model to None if loading fails\r\n\r\n\r\ndef perform_segmentation(image: np.ndarray):\r\n    \"\"\"\r\n    Performs segmentation on the input image using thresholding and contour filtering.\r\n    Optionally enhances with YOLO detection (if model loaded).\r\n\r\n    Args:\r\n        image: A NumPy array representing the preprocessed image (BGR format).\r\n\r\n    Returns:\r\n        A dictionary containing segmentation results, e.g.,\r\n        {'mask': binary_mask, 'contours': list_of_contours, 'yolo_results': yolo_results_object}\r\n        Returns None if processing fails.\r\n    \"\"\"\r\n    if image is None or image.size == 0:\r\n        logger.error(\"perform_segmentation received an invalid image.\")\r\n        return None\r\n\r\n    logger.info(f\"Performing segmentation on image with shape: {image.shape}\")\r\n\r\n    try:\r\n        # --- Basic Segmentation (Thresholding & Contours) ---\r\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n        # Apply CLAHE for contrast enhancement - useful for varying lighting\r\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\r\n        enhanced = clahe.apply(gray)\r\n\r\n        # Adaptive thresholding often works well for finding edges/regions\r\n        mask = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\r\n                                     cv2.THRESH_BINARY_INV, 25, 4)  # Adjust block size (25) and C (4) as needed\r\n\r\n        # Morphological operations to clean up the mask\r\n        kernel_size = 5  # Adjust kernel size as needed\r\n        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\r\n        # Closing fills small holes\r\n        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\r\n        # Opening removes small noise specks\r\n        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\r\n\r\n        # Find contours on the cleaned mask\r\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n        # Filter contours based on area (adjust min_area as needed)\r\n        min_contour_area = 300\r\n        filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\r\n\r\n        # Create a final mask from filtered contours\r\n        filtered_mask = np.zeros_like(mask)\r\n        cv2.drawContours(filtered_mask, filtered_contours, -1, 255, -1)  # Draw filled contours\r\n\r\n        logger.info(f\"Found {len(filtered_contours)} significant contours.\")\r\n\r\n        # --- Optional: Enhance with YOLO ---\r\n        yolo_results = None\r\n        if model is not None:\r\n            try:\r\n                # Run YOLO detection on the original image\r\n                results = model(image, verbose=False)  # verbose=False reduces console output\r\n                yolo_results = results[0]  # Get results for the first (only) image\r\n                logger.info(f\"YOLO detected {len(yolo_results.boxes)} objects.\")\r\n            except Exception as yolo_err:\r\n                logger.error(f\"Error during YOLO detection: {yolo_err}\", exc_info=True)\r\n        else:\r\n            logger.warning(\"YOLO model not loaded, skipping YOLO detection.\")\r\n\r\n        # Return results in a structured way\r\n        segmentation_output = {\r\n            'mask': filtered_mask,\r\n            'contours': filtered_contours,\r\n            'yolo_results': yolo_results  # Can be None if YOLO fails or isn't used\r\n        }\r\n        return segmentation_output\r\n\r\n    except cv2.error as cv_err:\r\n        logger.error(f\"OpenCV error during segmentation: {cv_err}\", exc_info=True)\r\n        return None\r\n    except Exception as e:\r\n        logger.error(f\"Unexpected error during segmentation: {e}\", exc_info=True)\r\n        return None\r\n\r\n\r\nclass SandPileApp:\r\n    def __init__(self, root):\r\n        self.root = root\r\n        self.root.title(\"Sand Pile Volume Estimator\")\r\n        self.material_type = tk.StringVar(value=\"Sand\")\r\n\r\n        self.top_image_path = None\r\n        self.front_image_path = None\r\n        self.tk_images = []\r\n\r\n        self.create_widgets()\r\n\r\n    def create_widgets(self):\r\n        frame = ttk.Frame(self.root)\r\n        frame.pack(padx=10, pady=10)\r\n\r\n        ttk.Label(frame, text=\"Select Material:\").grid(row=0, column=0, sticky='w')\r\n        ttk.Combobox(frame, textvariable=self.material_type, values=[\"Sand\", \"10mm Gravel\", \"20mm Gravel\"]).grid(row=0, column=1)\r\n\r\n        ttk.Button(frame, text=\"Upload Top View\", command=self.upload_top).grid(row=1, column=0, pady=5)\r\n        ttk.Button(frame, text=\"Upload Front View\", command=self.upload_front).grid(row=1, column=1, pady=5)\r\n        ttk.Button(frame, text=\"Process\", command=self.process).grid(row=2, column=0, columnspan=2, pady=10)\r\n\r\n        self.result_label = ttk.Label(frame, text=\"Detection Results Will Appear Below\", font=(\"Arial\", 10, \"bold\"))\r\n        self.result_label.grid(row=3, column=0, columnspan=2)\r\n\r\n        self.canvas = tk.Canvas(self.root, width=1800, height=1100)\r\n        self.canvas.pack()\r\n\r\n    def upload_top(self):\r\n        self.top_image_path = filedialog.askopenfilename()\r\n        messagebox.showinfo(\"Top View\", f\"Loaded: {self.top_image_path}\")\r\n\r\n    def upload_front(self):\r\n        self.front_image_path = filedialog.askopenfilename()\r\n        messagebox.showinfo(\"Front View\", f\"Loaded: {self.front_image_path}\")\r\n\r\n    def preprocess(self, path):\r\n        img = cv2.imread(path)\r\n        return cv2.resize(img, (640, 640))\r\n\r\n    def background_subtract(self, img):\r\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\r\n        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\r\n        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n        mask = np.zeros_like(gray)\r\n        for cnt in contours:\r\n            if cv2.contourArea(cnt) > 1000:\r\n                cv2.drawContours(mask, [cnt], -1, 255, -1)\r\n        return mask\r\n\r\n    def extract_foreground(self, img):\r\n        mask = self.background_subtract(img)\r\n        inverted_mask = cv2.bitwise_not(mask)  # 🔄 Invert the mask\r\n        foreground = np.zeros_like(img)\r\n        for c in range(3):\r\n            foreground[:, :, c] = img[:, :, c] * (inverted_mask // 255)\r\n        return foreground\r\n\r\n    def segment(self, img):\r\n        segmentation_result = perform_segmentation(img)\r\n        if segmentation_result:\r\n            return cv2.bitwise_and(img, img, mask=segmentation_result['mask'])\r\n        return img\r\n\r\n    def detect_objects(self, img):\r\n        results = model(img)\r\n        annotated = results[0].plot()\r\n        labels = [model.names[int(cls)] for cls in results[0].boxes.cls.cpu().numpy()]\r\n        return annotated, labels\r\n\r\n    def show_image(self, img, x, y, label):\r\n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n        pil_img = Image.fromarray(img_rgb)\r\n        pil_img = pil_img.resize((280, 280))\r\n        tk_img = ImageTk.PhotoImage(pil_img)\r\n\r\n        self.canvas.create_image(x, y, anchor=\"nw\", image=tk_img)\r\n        self.canvas.create_text(x + 140, y - 10, text=label, font=(\"Arial\", 10, \"bold\"))\r\n        self.tk_images.append(tk_img)\r\n\r\n    def show_raw_input(self, path, x, y, label):\r\n        img = Image.open(path).resize((280, 280))\r\n        tk_img = ImageTk.PhotoImage(img)\r\n        self.canvas.create_image(x, y, anchor=\"nw\", image=tk_img)\r\n        self.canvas.create_text(x + 140, y - 10, text=label, font=(\"Arial\", 10, \"bold\"))\r\n        self.tk_images.append(tk_img)\r\n\r\n    def process(self):\r\n        if not self.top_image_path or not self.front_image_path:\r\n            messagebox.showerror(\"Error\", \"Please upload both views.\")\r\n            return\r\n\r\n        self.canvas.delete(\"all\")\r\n        self.tk_images.clear()\r\n\r\n        self.show_raw_input(self.top_image_path, 50, 50, \"Input - Top View\")\r\n        self.show_raw_input(self.front_image_path, 50, 400, \"Input - Front View\")\r\n\r\n        # Top View Processing\r\n        top_img = self.preprocess(self.top_image_path)\r\n        top_fg = self.extract_foreground(top_img)\r\n        top_seg = self.segment(top_fg)\r\n        top_detected, top_labels = self.detect_objects(top_seg)\r\n\r\n        # Front View Processing\r\n        front_img = self.preprocess(self.front_image_path)\r\n        front_fg = self.extract_foreground(front_img)\r\n        front_seg = self.segment(front_fg)\r\n        front_detected, front_labels = self.detect_objects(front_seg)\r\n\r\n        # Display Results\r\n        self.show_image(top_fg, 350, 50, \"Top - Foreground\")\r\n        self.show_image(top_seg, 650, 50, \"Top - Segmented\")\r\n        self.show_image(top_detected, 950, 50, \"Top - Detection\")\r\n\r\n        self.show_image(front_fg, 350, 400, \"Front - Foreground\")\r\n        self.show_image(front_seg, 650, 400, \"Front - Segmented\")\r\n        self.show_image(front_detected, 950, 400, \"Front - Detection\")\r\n\r\n        result_text = (\r\n            f\"Material: {self.material_type.get()}\\n\\n\"\r\n            f\"Top View Detected: {top_labels}\\n\"\r\n            f\"Front View Detected: {front_labels}\"\r\n        )\r\n        self.result_label.config(text=result_text)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    root = tk.Tk()\r\n    app = SandPileApp(root)\r\n    root.mainloop()"
        }
    ]
}